{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import datetime\n",
    "#import gradio as gr\n",
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "from mimetypes import guess_type\n",
    "from openai import AzureOpenAI\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#setting up the environment\n",
    "#model and quota availaibility check to be added as part of release 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "# Azure OpenAI\n",
    "api_type: str = \"azure\"\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_version = \"2024-02-15-preview\"\n",
    "model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt4o_text(prompt):\n",
    "    \"\"\"\n",
    "    Gpt-4o model\n",
    "    \"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        api_key=api_key,\n",
    "        api_version=api_version,\n",
    "        base_url=f\"{api_base}/openai/deployments/{model}\",\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an artificial intelligence assistant designed to help you with information, answer your questions, and assist with a variety of tasks. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "result = gpt4o_text(\"Who are you?\")\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "result = gpt4o_text(\"What is the capital of France?\")\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An ARMA model, which stands for AutoRegressive Moving Average model, is a popular statistical method used in time series analysis to understand and predict future points in a series. It combines two key components:\n",
      "\n",
      "1. **AutoRegressive (AR) part**: This component represents the relationship between an observation and a number of lagged observations (previous values). It is essentially a linear regression of the current value of the series against one or more prior values of the series.\n",
      "\n",
      "2. **Moving Average (MA) part**: This component models the relationship between an observation and a residual error from a moving average model applied to lagged observations. It accounts for the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n",
      "\n",
      "An ARMA model is typically denoted as ARMA(p, q), where:\n",
      "- \\( p \\) is the order of the autoregressive part (the number of lagged observations included in the model).\n",
      "- \\( q \\) is the order of the moving average part (the number of lagged forecast errors in the prediction equation).\n",
      "\n",
      "The general form of an ARMA(p, q) model is:\n",
      "\n",
      "\\[ X_t = \\alpha + \\sum_{i=1}^{p} \\phi_i X_{t-i} + \\sum_{j=1}^{q} \\theta_j \\epsilon_{t-j} + \\epsilon_t \\]\n",
      "\n",
      "Where:\n",
      "- \\( X_t \\) is the time series at time \\( t \\).\n",
      "- \\( \\alpha \\) is the constant term.\n",
      "- \\( \\phi_i \\) are the parameters of the autoregressive part.\n",
      "- \\( \\theta_j \\) are the parameters of the moving average part.\n",
      "- \\( \\epsilon_t \\) is the white noise error term at time \\( t \\).\n",
      "\n",
      "ARMA models are useful for modeling time series data that show temporal dependencies and can help in forecasting future values based on past observations. However, they are best suited for stationary time series data, which means the statistical properties of the series (like mean and variance) do not change over time. For non-stationary data, ARIMA (AutoRegressive Integrated Moving Average) models, which include differencing to make the data stationary, are often used.\n"
     ]
    }
   ],
   "source": [
    "result = gpt4o_text(\"What is an ARMA model?\")\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Images:\n",
    "\n",
    "def gpt4o_url(image_url, prompt):\n",
    "    \"\"\"\n",
    "    Gpt-4o model using image url\n",
    "    \"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        api_key=api_key,\n",
    "        api_version=api_version,\n",
    "        base_url=f\"{api_base}/openai/deployments/{model}\",\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant to analyse images.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
